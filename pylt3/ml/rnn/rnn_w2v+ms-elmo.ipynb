{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-04-05 14:13:57,719: 'pattern' package found; tag filters are available for English\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Python\\projects\\PyLT3')\n",
    "\n",
    "from pylt3.ml.rnn.LazyTextDataset import LazyTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results reproducible\n",
    "random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(3)\n",
    "\n",
    "# run all numpy warnings as errors:\n",
    "np.seterr(all='raise')\n",
    "\n",
    "logging.basicConfig(format='[%(levelno)s] %(asctime)s: %(message)s', datefmt='%d-%b-%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec and/or ELMo and/or BERT initialisation\n",
    "use_ms = False\n",
    "\n",
    "use_google_w2v = False\n",
    "use_custom_w2v = False\n",
    "use_elmo = False\n",
    "use_bert = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-04-05 14:13:58,677: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\Bram\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "if use_ms:\n",
    "    from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "if len(list(filter(None, (use_google_w2v, use_custom_w2v)))) > 1:\n",
    "    raise ValueError(f\"Only one of 'use_google_w2v' or 'use_custom_w2v' can be used.\")\n",
    "else:\n",
    "    use_w2v = any((use_google_w2v, use_custom_w2v))\n",
    "    if use_w2v:\n",
    "        import gensim\n",
    "        if use_google_w2v:\n",
    "            embed_p = Path(r'C:\\Users\\Bram\\Downloads\\GoogleNews-vectors-negative300.bin').resolve()\n",
    "            w2v_model = gensim.models.KeyedVectors.load_word2vec_format(str(embed_p), binary=True)\n",
    "            # add a padding token with only zeros\n",
    "            # TODO: find alternative for unknown tokens. Zeros is NOT a good idea\n",
    "            w2v_model.add(['@pad@', '@unk@'], [np.zeros(w2v_model.vectors.shape[1]), np.zeros(w2v_model.vectors.shape[1])])\n",
    "        elif use_custom_w2v:\n",
    "            embed_p = Path('..\\..\\..\\data\\dpc\\ml\\other\\dpc+news2017.dim146-ep10-min2-win10-repl.w2v_model').resolve()\n",
    "            w2v_model = gensim.models.KeyedVectors.load_word2vec_format(str(embed_p))\n",
    "            # add a padding token with only zeros\n",
    "            w2v_model.add(['@pad@'], [np.zeros(w2v_model.vectors.shape[1])])\n",
    "            \n",
    "        w2v_config = {\n",
    "            'model': w2v_model,\n",
    "            'weights': torch.FloatTensor(w2v_model.vectors)\n",
    "        }\n",
    "    else:\n",
    "        w2v_config = None\n",
    "        \n",
    "if use_elmo:\n",
    "    from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "    elmo_config = {\n",
    "        'options_url': 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json',\n",
    "        'weights_url': 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
    "    }\n",
    "else:\n",
    "    elmo_config = None\n",
    "    \n",
    "if use_bert:\n",
    "    from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "    from pytorch_pretrained_bert.modeling import BertModel\n",
    "    # For OOM errors, see https://github.com/google-research/bert/blob/master/README.md#out-of-memory-issues\n",
    "    # Comes down to: lower max_seq_len and batch_size\n",
    "    bert_config = {\n",
    "        'tokenizer': BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True),\n",
    "        'model_str': 'bert-base-uncased',\n",
    "        'layers': '-1,-2,-3,-4',\n",
    "        'max_seq_len': 64\n",
    "    }\n",
    "else:\n",
    "    bert_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self, hidden_dim=512, ms_dim=None, w2v=None, elmo=None, bert=None, bidirectional=True, drop_prob=0):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ms_dim = ms_dim\n",
    "        self.w2v = w2v\n",
    "        self.elmo = elmo\n",
    "        self.bert = bert\n",
    "        self.bidirectional = bidirectional\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        input_fc = 0\n",
    "        \n",
    "        if ms_dim is not None:\n",
    "            self.ms_rnode = nn.GRU(ms_dim, hidden_dim, bidirectional=bidirectional, batch_first=True)\n",
    "            input_fc += hidden_dim\n",
    "            logging.info('Morphosyntactic features enabled...')\n",
    "            \n",
    "        if w2v is not None:\n",
    "            self.w2v = nn.Embedding.from_pretrained(w2v['weights'], freeze=True)        \n",
    "            self.w2v_rnode = nn.GRU(w2v['weights'].size(1), hidden_dim, bidirectional=bidirectional, batch_first=True)\n",
    "            input_fc += hidden_dim\n",
    "            logging.info('Word embeddings enabled...')\n",
    "        \n",
    "        if elmo is not None:\n",
    "            self.elmo = Elmo(elmo['options_url'], elmo['weights_url'], 1, dropout=drop_prob)\n",
    "#             self.elmo_rnode = nn.GRU(1024, hidden_dim, bidirectional=bidirectional)\n",
    "#             input_fc += hidden_dim\n",
    "            input_fc += 1024\n",
    "            logging.info('ELMo enabled...')\n",
    "            \n",
    "        if bert is not None:\n",
    "            self.bert = BertModel.from_pretrained(bert['model_str'])\n",
    "            # Freeze embeddings\n",
    "            for name, param in self.bert.named_parameters():                \n",
    "                if name.startswith('embeddings'):\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            self.bert_max_seq_len = bert['max_seq_len']\n",
    "            self.bert_layers = [int(l) for l in bert['layers'].split(',')]\n",
    "#             input_fc += 768 * len(self.bert_layers)\n",
    "            self.linear_bert = nn.Linear(768 * len(self.bert_layers), hidden_dim)\n",
    "            input_fc += hidden_dim\n",
    "            logging.info('Bert enabled...')\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob) if drop_prob > 0 else None\n",
    "        self.linear = nn.Linear(input_fc, 1)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.0000001)\n",
    "        \n",
    "    def _last_output(self, output, bidirectional=None):\n",
    "        bidirectional = self.bidirectional if bidirectional is None else bidirectional\n",
    "        if bidirectional:\n",
    "            sum_bi = output[:, :, :self.hidden_dim] + output[:, :, self.hidden_dim:]\n",
    "            last = sum_bi[:, -1, :]\n",
    "        else:\n",
    "            last = output[:, -1, :]\n",
    "    \n",
    "        return last    \n",
    "    \n",
    "    def forward(self, batch_size, ms_input=None, w2v_ids=None, elmo_ids=None, bert_input=None):      \n",
    "        if self.ms_dim is not None and ms_input is not None:\n",
    "            packed_ms_out, _ = self.ms_rnode(ms_input)\n",
    "#             print('packed ms output', packed_ms_out.data.size())            \n",
    "            # unpacked\n",
    "            unpacked_ms_out, ms_lengths = pad_packed_sequence(packed_ms_out, batch_first=True)\n",
    "#             print('unpacked ms input', unpacked_ms_out.size())\n",
    "            \n",
    "            if self.bidirectional:\n",
    "                # Sum two bidirectional layers\n",
    "                unpacked_ms_out = unpacked_ms_out[:, :, :self.hidden_dim] + unpacked_ms_out[:, :, self.hidden_dim:]\n",
    "#                 print('summed ms input', unpacked_ms_out.size())\n",
    "            # Get last item of each sequence, based on their *actual* lengths\n",
    "            final_ms = unpacked_ms_out[torch.arange(len(ms_lengths)), ms_lengths-1, :]\n",
    "#             print('final ms input', final_ms.size())\n",
    "        else:\n",
    "            final_ms = None\n",
    "        \n",
    "        if self.w2v is not None and w2v_ids is not None:            \n",
    "#             print('w2v_ids', w2v_ids.size())\n",
    "            w2v_out = self.w2v(w2v_ids)            \n",
    "#             print('w2v_out', w2v_out.size())\n",
    "            w2v_out, _ = self.w2v_rnode(w2v_out)\n",
    "            final_w2v = self._last_output(w2v_out)\n",
    "#             print('last w2v', final_w2v.size())\n",
    "        else:\n",
    "            final_w2v = None         \n",
    "                \n",
    "        if self.elmo is not None and elmo_ids is not None:\n",
    "            elmo_out = self.elmo(elmo_ids)\n",
    "            elmo_out = elmo_out['elmo_representations'][0]\n",
    "#             print('elmo representation size', elmo_out.size())\n",
    "#             elmo_out, _ = self.elmo_rnode(elmo_out)\n",
    "            \n",
    "#             final_elmo = self._last_output(elmo_out)\n",
    "            final_elmo = elmo_out[:, -1, :]\n",
    "#             print('last elmo', final_elmo.size())\n",
    "        else:\n",
    "            final_elmo = None\n",
    "        \n",
    "        if self.bert is not None and bert_input is not None:\n",
    "            bert_ids, bert_mask = bert_input\n",
    "            all_bert_layers, _ = self.bert(bert_ids, attention_mask=bert_mask)\n",
    "            bert_concat = torch.cat([all_bert_layers[i] for i in self.bert_layers], dim=-1)\n",
    "            # Pooling by also setting masked items to zero\n",
    "            bert_mask = bert_mask.to(torch.float).unsqueeze(2)\n",
    "            # Multiply output with mask \n",
    "            bert_pooled = bert_concat * bert_mask\n",
    "            \n",
    "#             print('bert pooled', bert_pooled.size())\n",
    "            \n",
    "            # First item ['CLS'] should be sentence representation\n",
    "            final_bert = bert_pooled[:, 0, :]\n",
    "            final_bert = self.linear_bert(final_bert)\n",
    "            \n",
    "            # FOR AVERAGING instead of taking CLS node\n",
    "            \"\"\"\n",
    "            # Sum items in sequence to get sentence representation\n",
    "            bert_summed = torch.sum(bert_pooled, dim=1).squeeze()\n",
    "            # Average over seq_length\n",
    "            final_bert = torch.div(bert_summed, self.bert_max_seq_len)\n",
    "            \"\"\"          \n",
    "            \n",
    "#             print('final bert', final_bert.size())\n",
    "        else:\n",
    "            final_bert = None  \n",
    "        \n",
    "        sentence_finals = [final for final in [final_w2v, final_elmo, final_bert] if final is not None]\n",
    "        \n",
    "        # Sentence features concatenate\n",
    "        if len(sentence_finals) > 1:\n",
    "            sentence_cat = torch.cat(sentence_finals, dim=1)\n",
    "        elif len(sentence_finals) == 1:\n",
    "            sentence_cat = sentence_finals[0]\n",
    "        else:\n",
    "            sentence_cat = None\n",
    "        \n",
    "        if sentence_cat is not None:\n",
    "#             print('sentence_cat', sentence_cat.size())\n",
    "            pass\n",
    "\n",
    "        # Concatenating    \n",
    "        if final_ms is not None and sentence_cat is not None:\n",
    "            sentence_ms_cat = torch.cat((sentence_cat, final_ms), dim=1)\n",
    "        elif final_ms is not None:\n",
    "            sentence_ms_cat = final_ms\n",
    "        elif sentence_cat is not None:\n",
    "            sentence_ms_cat = sentence_cat\n",
    "        \n",
    "#         print('sentence_ms_cat', sentence_ms_cat.size())\n",
    "            \n",
    "        # Only use the last item's output\n",
    "        if self.drop_prob > 0:\n",
    "            sentence_ms_cat = self.dropout(sentence_ms_cat)\n",
    "        \n",
    "        regression = self.linear(sentence_ms_cat)\n",
    "        regression = self.lrelu(regression)\n",
    "        \n",
    "#         print('regression', regression.size())\n",
    "\n",
    "        return regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionRNN:\n",
    "    def __init__(self, train_files=None, valid_files=None, test_files=None, ms_dim=None, use_w2v=False,\n",
    "                 use_elmo=False, bert=None, batch_size=(64, 64)):\n",
    "        print('Using torch ' + torch.__version__)\n",
    "\n",
    "        self.datasets, self.dataloaders = RegressionRNN._set_data_loaders(train_files, valid_files, test_files, batch_size)\n",
    "        self.device = RegressionRNN._set_device()\n",
    "        \n",
    "        self.use_ms = True if ms_dim is not None else False\n",
    "        self.ms_dim = ms_dim\n",
    "        self.use_w2v = use_w2v\n",
    "        self.use_elmo = use_elmo\n",
    "        \n",
    "        self.use_bert = True if bert is not None else False\n",
    "        self.bert_tokenizer = bert_config['tokenizer'] if bert is not None else None\n",
    "        self.bert_max_seq_len = bert_config['max_seq_len'] if bert else None\n",
    "        \n",
    "        self.use_sentences = any((use_w2v, use_elmo, self.use_bert))\n",
    "        \n",
    "        if len(list(filter(None, [self.use_ms, self.use_sentences]))) + 1 != len(train_files):\n",
    "            logging.warning('The number of input files is not the same as the number of enabled features.'\n",
    "                            ' Be warned!')\n",
    "        \n",
    "        self.model = None\n",
    "        self.w2v_vocab = None\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "        self.bert_optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.checkpoint_f = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_data_loaders(train_files, valid_files, test_files, batch_size):\n",
    "        RegressionRNN._verify_input(train_files, valid_files, test_files)\n",
    "\n",
    "        datasets = {\n",
    "            'train': LazyTextDataset(train_files) if train_files is not None else None,\n",
    "            'valid': LazyTextDataset(valid_files) if valid_files is not None else None,\n",
    "            'test': LazyTextDataset(test_files) if test_files is not None else None\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"Training set size: {len(datasets['train'])}\")\n",
    "        \n",
    "        if valid_files:\n",
    "            logging.info(f\"Validation set size: {len(datasets['valid'])}\")\n",
    "        if test_files:\n",
    "            logging.info(f\"Test set size: {len(datasets['test'])}\")                     \n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(datasets['train'], batch_size=batch_size[0], shuffle=True, num_workers=6) if train_files is not None else None,\n",
    "            'valid': DataLoader(datasets['valid'], batch_size=batch_size[1], shuffle=True, num_workers=6) if valid_files is not None else None,\n",
    "            'test': DataLoader(datasets['test'], batch_size=batch_size[1], shuffle=True, num_workers=6) if test_files is not None else None\n",
    "        }\n",
    "\n",
    "        return datasets, dataloaders\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_device():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            device_id = torch.cuda.current_device()\n",
    "            logging.info(f\"Using GPU {torch.cuda.get_device_name(device_id)}\")\n",
    "            # logging.info('Memory Usage:')\n",
    "            # logging.info('Allocated:', round(torch.cuda.memory_allocated(device_id) / 1024 ** 3, 1), 'GB')\n",
    "            # logging.info('Cached:   ', round(torch.cuda.memory_cached(device_id) / 1024 ** 3, 1), 'GB')\n",
    "        else:\n",
    "            logging.info('Using CPU...')\n",
    "\n",
    "        return device\n",
    "\n",
    "    @staticmethod\n",
    "    def _verify_input(train_files, test_files, valid_files):\n",
    "        for f_kind in [train_files, test_files, valid_files]:\n",
    "            if f_kind is None:\n",
    "                continue\n",
    "\n",
    "            for f in f_kind:\n",
    "                if not Path(f).resolve().is_file():\n",
    "                    raise ValueError(f\"Input file {str(f)} does not exist.\")  \n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_lines(data, split_on=None, cast_to=None):\n",
    "        out = []\n",
    "        for line in data:\n",
    "            line = line.strip()\n",
    "            if split_on:\n",
    "                line = line.split(split_on)\n",
    "                line = list(filter(None, line))\n",
    "            else:\n",
    "                line = [line] \n",
    "\n",
    "            if cast_to is not None:\n",
    "                line = [cast_to(l) for l in line]\n",
    "                \n",
    "            out.append(line)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def prepare_ms(self, data):\n",
    "        def pad_array(data, max_size):\n",
    "            \"\"\" Pad all 'sentences' to the size of the largest sentence. \"\"\"\n",
    "            # number of features in deepest list\n",
    "            feature_size = len(data[0][0])\n",
    "\n",
    "            for idx, arr in enumerate(data):\n",
    "                # If the list is smaller than the largest list -> pad it\n",
    "                if len(arr) < max_size:\n",
    "                    # Create a new zero-only array\n",
    "                    pad = np.zeros((max_size, feature_size), dtype=np.int8)\n",
    "                    # Replace the first part with the actual list\n",
    "                    pad[:len(arr)] = arr\n",
    "                    # Replace in-place in the top-level list\n",
    "                    data[idx] = pad\n",
    "\n",
    "            return np.array(data).reshape(-1, max_size, feature_size)\n",
    "\n",
    "        seqs = []\n",
    "        # Data is a 'text' of 'sentences'\n",
    "        for line in data:\n",
    "            # Every line is a 'sentence' of tab-separated 'tokens' \n",
    "            line = line.strip()\n",
    "            # Every token is a 'word' which is a list of 0s and 1s\n",
    "            tokens = line.split('\\t')\n",
    "            tokens = [list((map(int, token.split(' ')))) for token in tokens]            \n",
    "            seqs.append(np.array(tokens))      \n",
    "                         \n",
    "        \n",
    "        # Get the length of the not-padded sequences\n",
    "        lengths = torch.LongTensor([len(s) for s in seqs])\n",
    "        \n",
    "        # Create zero-only dataset                 \n",
    "        seq_tensor = torch.zeros(len(seqs), lengths.max(), self.ms_dim)\n",
    "        \n",
    "        # Fill in real values                 \n",
    "        for idx, (seq, seqlen) in enumerate(zip(seqs, lengths)):\n",
    "            seq_tensor[idx, :seqlen] = torch.FloatTensor(seq)              \n",
    "\n",
    "        # Gets back sorted lengths and the indices of sorted items\n",
    "        lengths, sorted_idxs = torch.sort(lengths, dim=0, descending=True)\n",
    "        # Sort tensor by using sorted indices\n",
    "#         print(sorted_idxs)\n",
    "        seq_tensor = seq_tensor[sorted_idxs, :, :]\n",
    "        # Pack sequences\n",
    "        packed_seqs = pack_padded_sequence(seq_tensor, lengths, batch_first=True)\n",
    "        \n",
    "        return packed_seqs, sorted_idxs\n",
    "                         \n",
    "    def prepare_w2v(self, data):\n",
    "        \"\"\" Gets the word2vec ID of the tokens.\n",
    "            Input is a batch of sentences, consisting of tokens. \"\"\"\n",
    "        idxs = []\n",
    "        # Get size of longest sequence\n",
    "        max_length = max([len(seq) for seq in data])\n",
    "\n",
    "        for seq in data:\n",
    "            tok_idxs = []\n",
    "            for word in seq:\n",
    "                try:\n",
    "                    tok_idxs.append(self.w2v_vocab[word].index)\n",
    "                except KeyError:\n",
    "                    tok_idxs.append(self.w2v_vocab['@unk@'].index)\n",
    "            \n",
    "            # Pad current sequence if smaller than largest sequence\n",
    "            seq_length = len(seq)\n",
    "            if seq_length < max_length:\n",
    "                tok_idxs.extend([self.w2v_vocab['@pad@'].index] * (max_length - seq_length))\n",
    "\n",
    "            idxs.append(tok_idxs)\n",
    "        \n",
    "        idxs = torch.LongTensor(idxs)\n",
    "        return idxs   \n",
    "                                 \n",
    "    @staticmethod\n",
    "    def prepare_elmo(sentences):\n",
    "        # Add <S> and </S> tokens to sentence\n",
    "        # See https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md#notes-on-statefulness-and-non-determinism        \n",
    "        elmo_sentences = []\n",
    "        for s in sentences:\n",
    "            elmo_sentences.append(['<S>', *s, '</S>'])\n",
    "        \n",
    "        return elmo_sentences\n",
    "    \n",
    "    def prepare_bert(self, sentences):\n",
    "        all_input_ids = []\n",
    "        all_input_mask = []\n",
    "        for sentence in sentences:\n",
    "            sentence = ' '.join(sentence)\n",
    "            # tokenizer will also separate on punctuation\n",
    "            # see https://github.com/google-research/bert#tokenization\n",
    "            tokens = self.bert_tokenizer.tokenize(sentence)\n",
    "\n",
    "            # limit size of tokens\n",
    "            if len(tokens) > self.bert_max_seq_len - 2:\n",
    "                tokens = tokens[0:(self.bert_max_seq_len - 2)]\n",
    "\n",
    "            # add [CLS] and [SEP], as expected in BERT\n",
    "            tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "\n",
    "            input_type_ids = [0] * len(tokens)\n",
    "            input_ids = self.bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            while len(input_ids) < self.bert_max_seq_len:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_input_mask.append(input_mask)\n",
    "        \n",
    "        all_input_ids = torch.LongTensor(all_input_ids)\n",
    "        all_input_mask = torch.LongTensor(all_input_mask)\n",
    "                         \n",
    "        return all_input_ids, all_input_mask                             \n",
    "                         \n",
    "    @staticmethod\n",
    "    def _plot_training(train_losses, valid_losses):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(valid_losses, label='Validation loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.title('Loss progress')\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig('progress.png')\n",
    "                \n",
    "    def train(self, epochs=10, checkpoint_f='checkpoint.pth', log_update_freq=0, patience=None):\n",
    "        logging.info('Training started.')        \n",
    "        train_start = time.time()\n",
    "        \n",
    "        self.checkpoint_f = checkpoint_f\n",
    "\n",
    "        valid_loss_min = np.inf\n",
    "        train_losses, valid_losses = [], []\n",
    "        last_saved_epoch = 0\n",
    "        # keep\n",
    "        total_train_time = 0\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            train_loss, train_results = self._process('train', log_update_freq, epoch)\n",
    "            total_train_time += time.time() - epoch_start\n",
    "            \n",
    "            valid_loss, valid_results = self._process('valid', log_update_freq, epoch)\n",
    "            \n",
    "            try:\n",
    "                train_pearson = pearsonr(train_results['predictions'], train_results['targets'])\n",
    "            except FloatingPointError:\n",
    "                train_pearson = \"Could not calculate Pearsonr\"\n",
    "            \n",
    "            try:\n",
    "                valid_pearson = pearsonr(valid_results['predictions'], valid_results['targets'])\n",
    "            except FloatingPointError:\n",
    "                valid_pearson = \"Could not calculate Pearsonr\"\n",
    "            \n",
    "            # calculate average losses\n",
    "            train_loss = np.mean(train_loss)\n",
    "            valid_loss = np.mean(valid_loss)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "            # print training/validation statistics            \n",
    "            logging.info(f\"Epoch {epoch} - completed in {(time.time() - epoch_start):.0f} seconds\\n\"\n",
    "                         f\"Training Loss: {train_loss:.6f}\\t Pearson: {train_pearson}\\n\"\n",
    "                         f\"Validation loss: {valid_loss:.6f}\\t Pearson: {valid_pearson}\")\n",
    "            \n",
    "            # save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                logging.info(f'!! Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).')\n",
    "                logging.info(f'!! Saving model as {self.checkpoint_f}...')\n",
    "                \n",
    "                torch.save(self.model.state_dict(), self.checkpoint_f)\n",
    "                last_saved_epoch = epoch                         \n",
    "                valid_loss_min = valid_loss\n",
    "            else:\n",
    "                logging.info(f\"!! Valid loss not improved. (Min. = {valid_loss_min}; last save at ep. {last_saved_epoch})\")\n",
    "                if train_loss <= valid_loss:\n",
    "                    logging.warning(f\"!! Training loss is lte validation loss. Might be overfitting!\")\n",
    "            \n",
    "            # Early-stopping\n",
    "            if patience is not None:\n",
    "                if (epoch - last_saved_epoch) == patience:\n",
    "                    logging.info(f\"Stopping early at epoch {epoch} (patience={patience})...\")\n",
    "                    break\n",
    "            \n",
    "            # Optimise with scheduler\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(valid_loss)\n",
    "            \n",
    "        RegressionRNN._plot_training(train_losses, valid_losses)\n",
    "        \n",
    "        logging.info(f\"Training completed in {(time.time() - train_start):.0f} seconds\"\n",
    "                     f\"\\nMin. valid loss: {valid_loss_min}\\nLast saved epoch: {last_saved_epoch}\"\n",
    "                     f\"\\nPerformance: {len(self.datasets['train'])//total_train_time:.0f} sentences/s\")\n",
    "\n",
    "    def _process(self, do, log_update_freq, epoch=None):\n",
    "        if do not in ('train', 'valid', 'test'):\n",
    "            raise ValueError(\"Use 'train', 'valid', or 'test' for 'do'.\")\n",
    "        \n",
    "        results = {'predictions': np.array([]), 'targets': np.array([])}\n",
    "        losses = np.array([])\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if do == 'train':\n",
    "            self.model.train()            \n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        \n",
    "        if log_update_freq:\n",
    "            nro_batches = len(self.datasets[do]) // self.dataloaders[do].batch_size\n",
    "            update_interval = nro_batches * (log_update_freq/100)\n",
    "            update_checkpoints = {int(nro_batches-(i*update_interval)) for i in range((100//log_update_freq))}\n",
    "        \n",
    "        for batch_idx, data in enumerate(self.dataloaders[do], 1):\n",
    "            # 0. Clear gradients\n",
    "            if do == 'train':                \n",
    "                self.optimizer.zero_grad()\n",
    "                if self.use_bert and self.bert_optimizer is not None:\n",
    "                    self.bert_optimizer.zero_grad()                     \n",
    "                \n",
    "            # 1. Data prep\n",
    "            if self.use_ms:\n",
    "                ms = data[0]\n",
    "                if self.use_sentences:\n",
    "                    sentence = data[1]\n",
    "            elif self.use_sentences:\n",
    "                sentence = data[0]\n",
    "                     \n",
    "            target = data[-1]\n",
    "                     \n",
    "            # Convert ms features to int array\n",
    "            if self.use_ms: \n",
    "                ms, sorted_ids = self.prepare_ms(ms)\n",
    "                ms = ms.to(self.device)\n",
    "            else:\n",
    "                ms = None\n",
    "            \n",
    "            # Convert sentence to token array\n",
    "            if self.use_sentences:\n",
    "                sentence = self.prepare_lines(sentence, split_on=' ')\n",
    "            \n",
    "            # Convert tokens to word2vec IDs\n",
    "            if self.use_w2v:\n",
    "                w2v_ids = self.prepare_w2v(sentence)\n",
    "                w2v_ids = w2v_ids[sorted_ids] if ms is not None else w2v_ids\n",
    "                w2v_ids = w2v_ids.to(self.device)\n",
    "            else:\n",
    "                w2v_ids = None   \n",
    "            \n",
    "            if self.use_elmo:\n",
    "                elmo_sentence = RegressionRNN.prepare_elmo(sentence)\n",
    "                elmo_ids = batch_to_ids(elmo_sentence)                     \n",
    "                elmo_ids = elmo_ids[sorted_ids] if self.use_ms else elmo_ids\n",
    "                elmo_ids = elmo_ids.to(self.device)\n",
    "            else:\n",
    "                elmo_ids = None\n",
    "            \n",
    "            if self.use_bert:\n",
    "                bert_ids, bert_mask = self.prepare_bert(sentence)                     \n",
    "                bert_ids = bert_ids[sorted_ids] if self.use_ms else bert_ids\n",
    "                bert_mask = bert_mask[sorted_ids] if self.use_ms else bert_mask\n",
    "                     \n",
    "                bert_ids = bert_ids.to(self.device)\n",
    "                bert_mask = bert_mask.to(self.device)\n",
    "                bert_input = (bert_ids, bert_mask)\n",
    "            else:\n",
    "                bert_input = None\n",
    "            \n",
    "            # Convert target to float array\n",
    "            target = torch.Tensor(self.prepare_lines(target, cast_to=float))\n",
    "            target = target[sorted_ids] if self.use_ms else target\n",
    "            # Get current batch size\n",
    "            curr_batch_size = target.size(0)           \n",
    "                     \n",
    "            target = target.to(self.device)   \n",
    "\n",
    "            # 2. Predictions\n",
    "            pred = self.model(curr_batch_size, ms, w2v_ids, elmo_ids, bert_input)\n",
    "            loss = self.criterion(pred, target)\n",
    "                    \n",
    "            # 3. Optimise during training\n",
    "            if do == 'train':\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.use_bert and self.bert_optimizer is not None:\n",
    "                    self.bert_optimizer.step()\n",
    "            \n",
    "            # 4. Save results\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            \n",
    "            results['predictions'] = np.append(results['predictions'], pred, axis=None)            \n",
    "            results['targets'] = np.append(results['targets'], target, axis=None)\n",
    "            losses = np.append(losses, float(loss))\n",
    "\n",
    "            if log_update_freq and batch_idx in update_checkpoints:\n",
    "                if do in ('train', 'valid'):\n",
    "                    logging.info(f\"{do.capitalize()} epoch {epoch}, batch nr. {batch_idx}/{nro_batches}...\")\n",
    "                else:                        \n",
    "                    logging.info(f\"{do.capitalize()}, batch nr. {batch_idx}/{nro_batches}...\")\n",
    "        \n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        return losses, results\n",
    "\n",
    "    def test(self, checkpoint_f='checkpoint.pth', log_update_freq=0):\n",
    "        logging.info('Testing started.')\n",
    "        test_start = time.time()\n",
    "        \n",
    "        if self.checkpoint_f is None:\n",
    "            self.model.load_state_dict(torch.load(checkpoint_f, map_location=self.device))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(self.checkpoint_f, map_location=self.device))\n",
    "\n",
    "        test_loss, test_results = self._process('test', log_update_freq)\n",
    "\n",
    "        try:\n",
    "            test_pearson = pearsonr(test_results['predictions'], test_results['targets'])\n",
    "        except FloatingPointError:\n",
    "            test_pearson = \"Could not calculate Pearsonr\"\n",
    "        \n",
    "        test_loss = np.mean(test_loss)\n",
    "        \n",
    "        logging.info(f\"Testing completed in {(time.time() - test_start):.0f} seconds\"\n",
    "                     f\"\\nLoss: {test_loss:.6f}\\t Pearson: {test_pearson}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-04-05 14:13:58,816: Training set size: 113633\n",
      "[INFO] 2019-04-05 14:13:58,817: Validation set size: 8000\n",
      "[INFO] 2019-04-05 14:13:58,818: Test set size: 8000\n",
      "[INFO] 2019-04-05 14:13:59,019: Using GPU GeForce GTX 1080 Ti\n",
      "[INFO] 2019-04-05 14:13:59,813: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\Bram\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[INFO] 2019-04-05 14:13:59,815: extracting archive file C:\\Users\\Bram\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\Bram\\AppData\\Local\\Temp\\tmpp1dbfa87\n",
      "[INFO] 2019-04-05 14:14:02,611: Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO] 2019-04-05 14:14:04,387: Bert enabled...\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 512\n",
    "MS_SIZE = 102 if use_ms else None\n",
    "\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\dpc.tok.norm.clean.cut.en.train',                                  \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\dpc.tok.norm.clean.cut.en.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\dpc.tok.norm.clean.cut.en.test',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}\n",
    "\n",
    "regr = RegressionRNN(**files,\n",
    "                     ms_dim = MS_SIZE,\n",
    "                     use_w2v=use_w2v,\n",
    "                     use_elmo=use_elmo,\n",
    "                     bert=bert_config,\n",
    "                     batch_size=(64, 64))\n",
    "\n",
    "if use_w2v:\n",
    "    regr.w2v_vocab = w2v_config['model'].vocab        \n",
    "\n",
    "regr.model = Regressor(HIDDEN_DIM, \n",
    "                       ms_dim=MS_SIZE, \n",
    "                       w2v=w2v_config,\n",
    "                       elmo=elmo_config,\n",
    "                       bert=bert_config,\n",
    "                       bidirectional=True,\n",
    "                       drop_prob=0)\n",
    "\n",
    "regr.criterion = nn.MSELoss()\n",
    "regr.optimizer = BertAdam([p for p in regr.model.parameters() if p.requires_grad],\n",
    "                          lr=0.00002,\n",
    "                          weight_decay=0.0002)\n",
    "\n",
    "\n",
    "# regr.optimizer = optim.Adam([\n",
    "#     {'params': [p for name, p in regr.model.named_parameters() if p.requires_grad and not name.startswith('bert')],\n",
    "#      'lr': 0.001},\n",
    "#     {'params': [p for p in regr.model.bert.parameters() if p.requires_grad],\n",
    "#      'lr': 0.00002,\n",
    "#      'weight_decay': 0.0002}\n",
    "# ])\n",
    "\n",
    "# regr.scheduler = optim.lr_scheduler.ReduceLROnPlateau(regr.optimizer, 'min', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-04-05 14:14:04,393: Training started.\n",
      "[INFO] 2019-04-05 14:18:00,103: Train epoch 0, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 14:21:48,965: Train epoch 0, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 14:25:38,337: Train epoch 0, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 14:29:25,903: Train epoch 0, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 14:29:33,884: Valid epoch 0, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 14:29:38,068: Valid epoch 0, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 14:29:42,257: Valid epoch 0, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 14:29:46,587: Valid epoch 0, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 14:29:47,088: Epoch 0 - completed in 943 seconds\n",
      "Training Loss: 0.869951\t Pearson: (0.5382343282530364, 0.0)\n",
      "Validation loss: 0.814622\t Pearson: (0.6041600904522285, 0.0)\n",
      "[INFO] 2019-04-05 14:29:47,089: !! Validation loss decreased (inf --> 0.814622).\n",
      "[INFO] 2019-04-05 14:29:47,090: !! Saving model as checkpoint.pth...\n",
      "[INFO] 2019-04-05 14:33:37,369: Train epoch 1, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 14:37:25,213: Train epoch 1, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 14:41:12,937: Train epoch 1, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 14:45:00,607: Train epoch 1, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 14:45:08,525: Valid epoch 1, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 14:45:12,713: Valid epoch 1, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 14:45:16,912: Valid epoch 1, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 14:45:21,244: Valid epoch 1, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 14:45:21,747: Epoch 1 - completed in 934 seconds\n",
      "Training Loss: 0.663599\t Pearson: (0.6765914708125582, 0.0)\n",
      "Validation loss: 0.802130\t Pearson: (0.6142270488179139, 0.0)\n",
      "[INFO] 2019-04-05 14:45:21,748: !! Validation loss decreased (0.814622 --> 0.802130).\n",
      "[INFO] 2019-04-05 14:45:21,749: !! Saving model as checkpoint.pth...\n",
      "[INFO] 2019-04-05 14:49:11,986: Train epoch 2, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 14:52:59,693: Train epoch 2, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 14:56:47,557: Train epoch 2, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 15:00:36,789: Train epoch 2, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 15:00:44,737: Valid epoch 2, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 15:00:48,965: Valid epoch 2, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 15:00:53,194: Valid epoch 2, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 15:00:57,564: Valid epoch 2, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 15:00:58,061: Epoch 2 - completed in 936 seconds\n",
      "Training Loss: 0.491250\t Pearson: (0.77375039321322, 0.0)\n",
      "Validation loss: 0.839699\t Pearson: (0.5980055023871322, 0.0)\n",
      "[INFO] 2019-04-05 15:00:58,062: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 15:00:58,063: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 15:04:50,203: Train epoch 3, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 15:08:40,267: Train epoch 3, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 15:12:29,183: Train epoch 3, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 15:16:17,497: Train epoch 3, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 15:16:25,477: Valid epoch 3, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 15:16:29,669: Valid epoch 3, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 15:16:33,865: Valid epoch 3, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 15:16:38,202: Valid epoch 3, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 15:16:38,710: Epoch 3 - completed in 941 seconds\n",
      "Training Loss: 0.365121\t Pearson: (0.8375826355109078, 0.0)\n",
      "Validation loss: 0.871981\t Pearson: (0.5908583140375626, 0.0)\n",
      "[INFO] 2019-04-05 15:16:38,711: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 15:16:38,713: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 15:20:29,076: Train epoch 4, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 15:24:17,343: Train epoch 4, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 15:28:05,500: Train epoch 4, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 15:31:55,591: Train epoch 4, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 15:32:03,443: Valid epoch 4, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 15:32:07,680: Valid epoch 4, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 15:32:11,904: Valid epoch 4, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 15:32:16,274: Valid epoch 4, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 15:32:16,779: Epoch 4 - completed in 938 seconds\n",
      "Training Loss: 0.282919\t Pearson: (0.8767978814564642, 0.0)\n",
      "Validation loss: 0.835079\t Pearson: (0.6030153947318505, 0.0)\n",
      "[INFO] 2019-04-05 15:32:16,780: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 15:32:16,780: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 15:36:08,889: Train epoch 5, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 15:39:58,153: Train epoch 5, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 15:43:48,603: Train epoch 5, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 15:47:39,834: Train epoch 5, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 15:47:47,810: Valid epoch 5, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 15:47:52,048: Valid epoch 5, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 15:47:56,269: Valid epoch 5, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 15:48:00,629: Valid epoch 5, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 15:48:01,150: Epoch 5 - completed in 944 seconds\n",
      "Training Loss: 0.227556\t Pearson: (0.9022269130754643, 0.0)\n",
      "Validation loss: 0.870067\t Pearson: (0.5929557727553847, 0.0)\n",
      "[INFO] 2019-04-05 15:48:01,151: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 15:48:01,151: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 15:51:52,932: Train epoch 6, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 15:55:42,080: Train epoch 6, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 15:59:30,572: Train epoch 6, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 16:03:19,117: Train epoch 6, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 16:03:26,916: Valid epoch 6, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 16:03:31,120: Valid epoch 6, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 16:03:35,331: Valid epoch 6, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 16:03:39,662: Valid epoch 6, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 16:03:40,147: Epoch 6 - completed in 939 seconds\n",
      "Training Loss: 0.190278\t Pearson: (0.9189579560622033, 0.0)\n",
      "Validation loss: 0.854668\t Pearson: (0.6060003625514144, 0.0)\n",
      "[INFO] 2019-04-05 16:03:40,148: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 16:03:40,149: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 16:07:30,863: Train epoch 7, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 16:11:18,909: Train epoch 7, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 16:15:06,985: Train epoch 7, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 16:18:55,299: Train epoch 7, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 16:19:03,181: Valid epoch 7, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 16:19:07,383: Valid epoch 7, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 16:19:11,593: Valid epoch 7, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 16:19:15,926: Valid epoch 7, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 16:19:16,416: Epoch 7 - completed in 936 seconds\n",
      "Training Loss: 0.164028\t Pearson: (0.9305500489423567, 0.0)\n",
      "Validation loss: 0.872814\t Pearson: (0.6012203956652796, 0.0)\n",
      "[INFO] 2019-04-05 16:19:16,417: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 16:19:16,418: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 16:23:07,378: Train epoch 8, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 16:26:55,910: Train epoch 8, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 16:30:44,342: Train epoch 8, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 16:34:32,812: Train epoch 8, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 16:34:40,730: Valid epoch 8, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 16:34:44,929: Valid epoch 8, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 16:34:49,129: Valid epoch 8, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 16:34:53,469: Valid epoch 8, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 16:34:53,954: Epoch 8 - completed in 938 seconds\n",
      "Training Loss: 0.145086\t Pearson: (0.9388379397360193, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.837476\t Pearson: (0.6032872907094705, 0.0)\n",
      "[INFO] 2019-04-05 16:34:53,955: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 16:34:53,956: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 16:38:45,246: Train epoch 9, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 16:42:34,024: Train epoch 9, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 16:46:23,177: Train epoch 9, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 16:50:11,336: Train epoch 9, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 16:50:19,256: Valid epoch 9, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 16:50:23,456: Valid epoch 9, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 16:50:27,652: Valid epoch 9, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 16:50:31,987: Valid epoch 9, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 16:50:32,480: Epoch 9 - completed in 939 seconds\n",
      "Training Loss: 0.128107\t Pearson: (0.946195428696679, 0.0)\n",
      "Validation loss: 0.838072\t Pearson: (0.6125835060887634, 0.0)\n",
      "[INFO] 2019-04-05 16:50:32,481: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 16:50:32,482: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 16:54:23,267: Train epoch 10, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 16:58:11,569: Train epoch 10, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 17:02:00,050: Train epoch 10, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 17:05:48,500: Train epoch 10, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 17:05:56,318: Valid epoch 10, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 17:06:00,522: Valid epoch 10, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 17:06:04,731: Valid epoch 10, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 17:06:09,065: Valid epoch 10, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 17:06:09,554: Epoch 10 - completed in 937 seconds\n",
      "Training Loss: 0.115407\t Pearson: (0.9516759039744142, 0.0)\n",
      "Validation loss: 0.862773\t Pearson: (0.6034391952140219, 0.0)\n",
      "[INFO] 2019-04-05 17:06:09,555: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 17:06:09,556: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 17:10:00,405: Train epoch 11, batch nr. 443/1775...\n",
      "[INFO] 2019-04-05 17:13:48,510: Train epoch 11, batch nr. 887/1775...\n",
      "[INFO] 2019-04-05 17:17:36,910: Train epoch 11, batch nr. 1331/1775...\n",
      "[INFO] 2019-04-05 17:21:25,423: Train epoch 11, batch nr. 1775/1775...\n",
      "[INFO] 2019-04-05 17:21:33,247: Valid epoch 11, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 17:21:37,451: Valid epoch 11, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 17:21:41,660: Valid epoch 11, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 17:21:45,984: Valid epoch 11, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 17:21:46,481: Epoch 11 - completed in 937 seconds\n",
      "Training Loss: 0.105106\t Pearson: (0.9560846999307053, 0.0)\n",
      "Validation loss: 0.828640\t Pearson: (0.6062017277337381, 0.0)\n",
      "[INFO] 2019-04-05 17:21:46,482: !! Valid loss not improved. (Min. = 0.8021301219463348; last save at ep. 1)\n",
      "[WARNING] 2019-04-05 17:21:46,483: !! Training loss is lte validation loss. Might be overfitting!\n",
      "[INFO] 2019-04-05 17:21:46,484: Stopping early at epoch 11 (patience=10)...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-04-05 17:21:46,607: Training completed in 11262 seconds\n",
      "Min. valid loss: 0.8021301219463348\n",
      "Last saved epoch: 1\n",
      "Performance: 10 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regr.train(epochs=100, log_update_freq=25, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-04-05 17:21:46,612: Testing started.\n",
      "[INFO] 2019-04-05 17:21:54,166: Test, batch nr. 31/125...\n",
      "[INFO] 2019-04-05 17:21:58,361: Test, batch nr. 62/125...\n",
      "[INFO] 2019-04-05 17:22:02,562: Test, batch nr. 93/125...\n",
      "[INFO] 2019-04-05 17:22:06,898: Test, batch nr. 125/125...\n",
      "[INFO] 2019-04-05 17:22:07,394: Testing completed in 21 seconds\n",
      "Loss: 0.781833\t Pearson: (0.6039205079285322, 0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr.test(log_update_freq=25)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sentences + MS\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\conll-feats.train',\n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\dpc.tok.norm.clean.cut.en.train',                                  \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\conll-feats.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\dpc.tok.norm.clean.cut.en.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\conll-feats.test',\n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\dpc.tok.norm.clean.cut.en.test',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}\n",
    "\n",
    "# MS\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\conll-feats.train',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\conll-feats.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\conll-feats.test',                               \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}\n",
    "\n",
    "# Sentences\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\dpc.tok.norm.clean.cut.en.train',                                  \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\dpc.tok.norm.clean.cut.en.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\dpc.tok.norm.clean.cut.en.test',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
