{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import argsort\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Python\\projects\\PyLT3')\n",
    "\n",
    "from pylt3.ml.rnn.LazyTextDataset import LazyTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results reproducible\n",
    "random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(3)\n",
    "\n",
    "# run all numpy warnings as errors:\n",
    "np.seterr(all='raise')\n",
    "\n",
    "logging.basicConfig(format='[%(levelno)s] %(asctime)s: %(message)s', datefmt='%d-%b-%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec and/or ELMo and/or BERT initialisation\n",
    "use_ms = True\n",
    "\n",
    "use_google_w2v = False\n",
    "use_custom_w2v = True\n",
    "use_elmo = False\n",
    "use_bert = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-05-22 16:10:05,234: loading projection weights from C:\\Python\\projects\\PyLT3\\data\\dpc\\prep\\dpc+news2017.norm.tok.low.en.w2v\n",
      "[INFO] 2019-05-22 16:12:09,235: loaded (711297, 300) matrix from C:\\Python\\projects\\PyLT3\\data\\dpc\\prep\\dpc+news2017.norm.tok.low.en.w2v\n"
     ]
    }
   ],
   "source": [
    "if use_ms:\n",
    "    from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pack_sequence\n",
    "\n",
    "if len(list(filter(None, (use_google_w2v, use_custom_w2v)))) > 1:\n",
    "    raise ValueError(f\"Only one of 'use_google_w2v' or 'use_custom_w2v' can be used.\")\n",
    "else:\n",
    "    use_w2v = any((use_google_w2v, use_custom_w2v))\n",
    "    if use_w2v:        \n",
    "        from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pack_sequence\n",
    "        import gensim\n",
    "        if use_google_w2v:\n",
    "            embed_p = Path(r'C:\\Users\\Bram\\Downloads\\GoogleNews-vectors-negative300.bin').resolve()\n",
    "            w2v_model = gensim.models.KeyedVectors.load_word2vec_format(str(embed_p), binary=True)\n",
    "        elif use_custom_w2v:\n",
    "            embed_p = Path('C:\\Python\\projects\\PyLT3\\data\\dpc\\prep\\dpc+news2017.norm.tok.low.en.w2v').resolve()\n",
    "            w2v_model = gensim.models.KeyedVectors.load_word2vec_format(str(embed_p))\n",
    "            \n",
    "        w2v_config = {\n",
    "            'model': w2v_model,\n",
    "            'weights': torch.FloatTensor(w2v_model.vectors)\n",
    "        }\n",
    "    else:\n",
    "        w2v_config = None\n",
    "        \n",
    "if use_elmo:\n",
    "    from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "    elmo_config = {\n",
    "        'options_url': 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json',\n",
    "        'weights_url': 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
    "    }\n",
    "else:\n",
    "    elmo_config = None\n",
    "    \n",
    "if use_bert:\n",
    "    from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "    from pytorch_pretrained_bert.modeling import BertModel\n",
    "    # For OOM errors, see https://github.com/google-research/bert/blob/master/README.md#out-of-memory-issues\n",
    "    # Comes down to: lower max_seq_len and batch_size\n",
    "    bert_config = {\n",
    "        'tokenizer': BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True),\n",
    "        'model_str': 'bert-base-uncased',\n",
    "        'layers': '-1,-2,-3,-4',\n",
    "        'max_seq_len': 64\n",
    "    }\n",
    "else:\n",
    "    bert_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self, hidden_dim=512, ms_dim=None, w2v=None, elmo=None, bert=None, bidirectional=True, drop_prob=0):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ms_dim = ms_dim\n",
    "        self.w2v = w2v\n",
    "        self.elmo = elmo\n",
    "        self.bert = bert\n",
    "        self.bidirectional = bidirectional\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        input_fc = 0\n",
    "        \n",
    "        if ms_dim is not None:\n",
    "            self.ms_rnode = nn.GRU(ms_dim, hidden_dim, bidirectional=bidirectional, batch_first=True)\n",
    "            input_fc += hidden_dim\n",
    "            logging.info('Morphosyntactic features enabled...')\n",
    "            \n",
    "        if w2v is not None:\n",
    "            self.w2v = nn.Embedding.from_pretrained(w2v['weights'], freeze=True)        \n",
    "            self.w2v_rnode = nn.GRU(w2v['weights'].size(1), hidden_dim, bidirectional=bidirectional, batch_first=True)\n",
    "            input_fc += hidden_dim\n",
    "            logging.info('Word embeddings enabled...')\n",
    "        \n",
    "        if elmo is not None:\n",
    "            self.elmo = Elmo(elmo['options_url'], elmo['weights_url'], 1, dropout=drop_prob)\n",
    "#             self.elmo_rnode = nn.GRU(1024, hidden_dim, bidirectional=bidirectional)\n",
    "#             input_fc += hidden_dim\n",
    "            input_fc += 1024\n",
    "            logging.info('ELMo enabled...')\n",
    "            \n",
    "        if bert is not None:\n",
    "            self.bert = BertModel.from_pretrained(bert['model_str'])\n",
    "            # Freeze embeddings\n",
    "            for name, param in self.bert.named_parameters():                \n",
    "                if name.startswith('embeddings'):\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            self.bert_max_seq_len = bert['max_seq_len']\n",
    "            self.bert_layers = [int(l) for l in bert['layers'].split(',')]\n",
    "#             input_fc += 768 * len(self.bert_layers)\n",
    "            self.linear_bert = nn.Linear(768 * len(self.bert_layers), hidden_dim)\n",
    "            input_fc += hidden_dim\n",
    "            logging.info('Bert enabled...')\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob) if drop_prob > 0 else None\n",
    "        self.linear = nn.Linear(input_fc, 1)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.0000001)\n",
    "        \n",
    "    def _last_output(self, output, bidirectional=None):\n",
    "        bidirectional = self.bidirectional if bidirectional is None else bidirectional\n",
    "        if bidirectional:\n",
    "            sum_bi = output[:, :, :self.hidden_dim] + output[:, :, self.hidden_dim:]\n",
    "            last = sum_bi[:, -1, :]\n",
    "        else:\n",
    "            last = output[:, -1, :]\n",
    "    \n",
    "        return last    \n",
    "    \n",
    "    def forward(self, batch_size, ms_input=None, packed_w2v_ids=None, elmo_ids=None, bert_input=None):      \n",
    "        if self.ms_dim is not None and ms_input is not None:\n",
    "            packed_ms_out, _ = self.ms_rnode(ms_input)\n",
    "#             print('packed ms output', packed_ms_out.data.size())            \n",
    "            # unpacked\n",
    "            unpacked_ms_out, ms_lengths = pad_packed_sequence(packed_ms_out, batch_first=True)\n",
    "            print('unpacked_ms_out', unpacked_ms_out.size())\n",
    "            \n",
    "            if self.bidirectional:\n",
    "                # Sum two bidirectional layers\n",
    "                unpacked_ms_out = unpacked_ms_out[:, :, :self.hidden_dim] + unpacked_ms_out[:, :, self.hidden_dim:]\n",
    "#                 print('summed ms input', unpacked_ms_out.size())\n",
    "            # Get last item of each sequence, based on their *actual* lengths\n",
    "            final_ms = unpacked_ms_out[torch.arange(len(ms_lengths)), ms_lengths-1, :]\n",
    "#             print('final ms input', final_ms.size())\n",
    "        else:\n",
    "            final_ms = None\n",
    "            \n",
    "        if self.w2v and packed_w2v_ids is not None:\n",
    "            # input is a packed sequence\n",
    "#             print('input', packed_w2v_ids.data)\n",
    "            packed_w2v_out = nn.utils.rnn.PackedSequence(self.w2v(packed_w2v_ids.data), packed_w2v_ids.batch_sizes)\n",
    "#             print('after embedding', packed_w2v_out)\n",
    "            packed_w2v_out, _ = self.w2v_rnode(packed_w2v_out)\n",
    "#             print('after gru', packed_w2v_out)\n",
    "            unpacked_w2v_out, w2v_lengths = pad_packed_sequence(packed_w2v_out, batch_first=True)\n",
    "            print('unpacked_w2v_out', unpacked_w2v_out.size())\n",
    "            if self.bidirectional:\n",
    "                unpacked_w2v_out = unpacked_w2v_out[:, :, :self.hidden_dim] + unpacked_w2v_out[:, :, self.hidden_dim:]\n",
    "#                 print('after bidirectional', unpacked_w2v_out)\n",
    "            # Get last item of each sequence, based on their *actual* lengths\n",
    "            final_w2v = unpacked_w2v_out[torch.arange(len(w2v_lengths)), w2v_lengths - 1, :]\n",
    "#             print('final', final_w2v)\n",
    "        else:\n",
    "            final_w2v = None\n",
    "                \n",
    "        if self.elmo is not None and elmo_ids is not None:\n",
    "            elmo_out = self.elmo(elmo_ids)\n",
    "            elmo_out = elmo_out['elmo_representations'][0]\n",
    "#             print('elmo representation size', elmo_out.size())\n",
    "#             elmo_out, _ = self.elmo_rnode(elmo_out)\n",
    "            \n",
    "#             final_elmo = self._last_output(elmo_out)\n",
    "            final_elmo = elmo_out[:, -1, :]\n",
    "#             print('last elmo', final_elmo.size())\n",
    "        else:\n",
    "            final_elmo = None\n",
    "        \n",
    "        if self.bert is not None and bert_input is not None:\n",
    "            bert_ids, bert_mask = bert_input\n",
    "            all_bert_layers, _ = self.bert(bert_ids, attention_mask=bert_mask)\n",
    "            bert_concat = torch.cat([all_bert_layers[i] for i in self.bert_layers], dim=-1)\n",
    "            # Pooling by also setting masked items to zero\n",
    "            bert_mask = bert_mask.to(torch.float).unsqueeze(2)\n",
    "            # Multiply output with mask \n",
    "            bert_pooled = bert_concat * bert_mask\n",
    "            \n",
    "#             print('bert pooled', bert_pooled.size())\n",
    "            \n",
    "            # First item ['CLS'] should be sentence representation\n",
    "            final_bert = bert_pooled[:, 0, :]\n",
    "            final_bert = self.linear_bert(final_bert)\n",
    "            \n",
    "            # FOR AVERAGING instead of taking CLS node\n",
    "            \"\"\"\n",
    "            # Sum items in sequence to get sentence representation\n",
    "            bert_summed = torch.sum(bert_pooled, dim=1).squeeze()\n",
    "            # Average over seq_length\n",
    "            final_bert = torch.div(bert_summed, self.bert_max_seq_len)\n",
    "            \"\"\"          \n",
    "            \n",
    "#             print('final bert', final_bert.size())\n",
    "        else:\n",
    "            final_bert = None  \n",
    "        \n",
    "        sentence_finals = [final for final in [final_w2v, final_elmo, final_bert] if final is not None]\n",
    "        \n",
    "        # Sentence features concatenate\n",
    "        if len(sentence_finals) > 1:\n",
    "            sentence_cat = torch.cat(sentence_finals, dim=1)\n",
    "        elif len(sentence_finals) == 1:\n",
    "            sentence_cat = sentence_finals[0]\n",
    "        else:\n",
    "            sentence_cat = None\n",
    "        \n",
    "        if sentence_cat is not None:\n",
    "            pass        \n",
    "        \n",
    "        # Concatenating    \n",
    "        if final_ms is not None and sentence_cat is not None:\n",
    "            sentence_ms_cat = torch.cat((sentence_cat, final_ms), dim=1)\n",
    "        elif final_ms is not None:\n",
    "            sentence_ms_cat = final_ms\n",
    "        elif sentence_cat is not None:\n",
    "            sentence_ms_cat = sentence_cat\n",
    "        \n",
    "        print('sentence_ms_cat', sentence_ms_cat.size())\n",
    "            \n",
    "        # Only use the last item's output\n",
    "        if self.drop_prob > 0:\n",
    "            sentence_ms_cat = self.dropout(sentence_ms_cat)\n",
    "        \n",
    "        regression = self.linear(sentence_ms_cat)\n",
    "        regression = self.lrelu(regression)\n",
    "        \n",
    "#         print('regression', regression.size())\n",
    "\n",
    "        return regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionRNN:\n",
    "    def __init__(self, train_files=None, valid_files=None, test_files=None, ms_dim=None, use_w2v=False,\n",
    "                 use_elmo=False, bert=None, batch_size=(64, 64, 64)):\n",
    "        print('Using torch ' + torch.__version__)\n",
    "\n",
    "        self.datasets, self.dataloaders = RegressionRNN._set_data_loaders(train_files, valid_files, test_files, batch_size)\n",
    "        self.device = RegressionRNN._set_device()\n",
    "        \n",
    "        self.use_ms = True if ms_dim is not None else False\n",
    "        self.ms_dim = ms_dim\n",
    "        self.use_w2v = use_w2v\n",
    "        self.use_elmo = use_elmo\n",
    "        \n",
    "        self.use_bert = True if bert is not None else False\n",
    "        self.bert_tokenizer = bert_config['tokenizer'] if bert is not None else None\n",
    "        self.bert_max_seq_len = bert_config['max_seq_len'] if bert else None\n",
    "        \n",
    "        self.use_sentences = any((use_w2v, use_elmo, self.use_bert))\n",
    "        \n",
    "        self.model = None\n",
    "        self.w2v_vocab = None\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "        self.bert_optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.checkpoint_f = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_data_loaders(train_files, valid_files, test_files, batch_size):\n",
    "        datasets = {\n",
    "            'train': LazyTextDataset(train_files) if train_files is not None else None,\n",
    "            'valid': LazyTextDataset(valid_files) if valid_files is not None else None,\n",
    "            'test': LazyTextDataset(test_files) if test_files is not None else None\n",
    "        }\n",
    "\n",
    "        if train_files:\n",
    "            logging.info(f\"Training set size: {len(datasets['train'])}\")\n",
    "        if valid_files:\n",
    "            logging.info(f\"Validation set size: {len(datasets['valid'])}\")\n",
    "        if test_files:\n",
    "            logging.info(f\"Test set size: {len(datasets['test'])}\")\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(datasets['train'], batch_size=batch_size[0], shuffle=True)\n",
    "            if train_files is not None else None,\n",
    "            'valid': DataLoader(datasets['valid'], batch_size=batch_size[1], shuffle=True)\n",
    "            if valid_files is not None else None,\n",
    "            'test': DataLoader(datasets['test'], batch_size=batch_size[2], shuffle=True)\n",
    "            if test_files is not None else None\n",
    "        }\n",
    "\n",
    "        return datasets, dataloaders\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_device():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            device_id = torch.cuda.current_device()\n",
    "            logging.info(f\"Using GPU {torch.cuda.get_device_name(device_id)}\")\n",
    "            # logging.info('Memory Usage:')\n",
    "            # logging.info('Allocated:', round(torch.cuda.memory_allocated(device_id) / 1024 ** 3, 1), 'GB')\n",
    "            # logging.info('Cached:   ', round(torch.cuda.memory_cached(device_id) / 1024 ** 3, 1), 'GB')\n",
    "        else:\n",
    "            logging.info('Using CPU...')\n",
    "\n",
    "        return device  \n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_lines(data, split_on=None, cast_to=None):\n",
    "        out = []\n",
    "        for line in data:\n",
    "            line = line.strip()\n",
    "            if split_on:\n",
    "                line = line.split(split_on)\n",
    "                line = list(filter(None, line))\n",
    "            else:\n",
    "                line = [line] \n",
    "\n",
    "            if cast_to is not None:\n",
    "                line = [cast_to(l) for l in line]\n",
    "                \n",
    "            out.append(line)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def prepare_ms(self, data):\n",
    "        def pad_array(data, max_size):\n",
    "            \"\"\" Pad all 'sentences' to the size of the largest sentence. \"\"\"\n",
    "            # number of features in deepest list\n",
    "            feature_size = len(data[0][0])\n",
    "\n",
    "            for idx, arr in enumerate(data):\n",
    "                # If the list is smaller than the largest list -> pad it\n",
    "                if len(arr) < max_size:\n",
    "                    # Create a new zero-only array\n",
    "                    pad = np.zeros((max_size, feature_size), dtype=np.int8)\n",
    "                    # Replace the first part with the actual list\n",
    "                    pad[:len(arr)] = arr\n",
    "                    # Replace in-place in the top-level list\n",
    "                    data[idx] = pad\n",
    "\n",
    "            return np.array(data).reshape(-1, max_size, feature_size)\n",
    "\n",
    "        seqs = []\n",
    "        # Data is a 'text' of 'sentences'\n",
    "        for line in data:\n",
    "            # Every line is a 'sentence' of tab-separated 'tokens' \n",
    "            line = line.strip()\n",
    "            # Every token is a 'word' which is a list of 0s and 1s\n",
    "            tokens = line.split('\\t')\n",
    "            tokens = [list((map(int, token.split(' ')))) for token in tokens]            \n",
    "            seqs.append(np.array(tokens))      \n",
    "                         \n",
    "        \n",
    "        # Get the length of the not-padded sequences\n",
    "        lengths = torch.LongTensor([len(s) for s in seqs])\n",
    "        \n",
    "        # Create zero-only dataset                 \n",
    "        seq_tensor = torch.zeros(len(seqs), lengths.max(), self.ms_dim)\n",
    "        \n",
    "        # Fill in real values                 \n",
    "        for idx, (seq, seqlen) in enumerate(zip(seqs, lengths)):\n",
    "            seq_tensor[idx, :seqlen] = torch.FloatTensor(seq)              \n",
    "\n",
    "        # Gets back sorted lengths and the indices of sorted items\n",
    "        lengths, sorted_idxs = torch.sort(lengths, dim=0, descending=True)\n",
    "        # Sort tensor by using sorted indices\n",
    "#         print(sorted_idxs)\n",
    "        seq_tensor = seq_tensor[sorted_idxs, :, :]\n",
    "        # Pack sequences\n",
    "        packed_seqs = pack_padded_sequence(seq_tensor, lengths, batch_first=True)\n",
    "        \n",
    "        return packed_seqs, sorted_idxs\n",
    "                         \n",
    "    def prepare_w2v(self, data):\n",
    "        \"\"\" Gets the word2vec ID of the tokens.\n",
    "            Input is a batch of sentences, consisting of tokens. \"\"\"\n",
    "        seqs = []\n",
    "        for line in data:\n",
    "            tok_idxs = []\n",
    "            for word in line:\n",
    "                try:\n",
    "                    tok_idxs.append(self.w2v_vocab[word].index)\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        tok_idxs.append(self.w2v_vocab['@unk@'].index)\n",
    "                    except KeyError:\n",
    "                        raise KeyError(\"The specified 'unknown_token' is not present in your word2vec model.\")\n",
    "\n",
    "            seqs.append(tok_idxs)\n",
    "        \n",
    "        # Get the length of the not-padded sequences\n",
    "        lengths = torch.LongTensor([len(s) for s in seqs])\n",
    "        # Get sorted indices\n",
    "        _, sorted_idxs = torch.sort(lengths, dim=0, descending=True)\n",
    "        # sort list. We cannot first torch it because sizes are not consistent\n",
    "        # and we can't pad it here yet\n",
    "        seqs.sort(key=len, reverse=True)\n",
    "        # pack (but don't pad)                 \n",
    "        packed_seqs = pack_sequence([torch.LongTensor(s) for s in seqs])\n",
    "\n",
    "        return packed_seqs, sorted_idxs   \n",
    "                                 \n",
    "    @staticmethod\n",
    "    def prepare_elmo(sentences):\n",
    "        # Add <S> and </S> tokens to sentence\n",
    "        # See https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md#notes-on-statefulness-and-non-determinism        \n",
    "        elmo_sentences = []\n",
    "        for s in sentences:\n",
    "            elmo_sentences.append(['<S>', *s, '</S>'])\n",
    "        \n",
    "        return elmo_sentences\n",
    "    \n",
    "    def prepare_bert(self, sentences):\n",
    "        all_input_ids = []\n",
    "        all_input_mask = []\n",
    "        for sentence in sentences:\n",
    "            sentence = ' '.join(sentence)\n",
    "            # tokenizer will also separate on punctuation\n",
    "            # see https://github.com/google-research/bert#tokenization\n",
    "            tokens = self.bert_tokenizer.tokenize(sentence)\n",
    "\n",
    "            # limit size of tokens\n",
    "            if len(tokens) > self.bert_max_seq_len - 2:\n",
    "                tokens = tokens[0:(self.bert_max_seq_len - 2)]\n",
    "\n",
    "            # add [CLS] and [SEP], as expected in BERT\n",
    "            tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "\n",
    "            input_type_ids = [0] * len(tokens)\n",
    "            input_ids = self.bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            while len(input_ids) < self.bert_max_seq_len:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_input_mask.append(input_mask)\n",
    "        \n",
    "        all_input_ids = torch.LongTensor(all_input_ids)\n",
    "        all_input_mask = torch.LongTensor(all_input_mask)\n",
    "                         \n",
    "        return all_input_ids, all_input_mask                             \n",
    "                         \n",
    "    @staticmethod\n",
    "    def _plot_training(train_losses, valid_losses):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(valid_losses, label='Validation loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.title('Loss progress')\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig('progress.png')\n",
    "                \n",
    "    def train(self, epochs=10, checkpoint_f='checkpoint.pth', log_update_freq=0, patience=None):\n",
    "        logging.info('Training started.')        \n",
    "        train_start = time.time()\n",
    "        \n",
    "        self.checkpoint_f = checkpoint_f\n",
    "\n",
    "        valid_loss_min = np.inf\n",
    "        train_losses, valid_losses = [], []\n",
    "        last_saved_epoch = 0\n",
    "        # keep\n",
    "        total_train_time = 0\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            train_loss, train_results = self._process('train', log_update_freq, epoch)\n",
    "            total_train_time += time.time() - epoch_start\n",
    "            \n",
    "            valid_loss, valid_results = self._process('valid', log_update_freq, epoch)\n",
    "            \n",
    "            try:\n",
    "                train_pearson = pearsonr(train_results['predictions'], train_results['targets'])\n",
    "            except FloatingPointError:\n",
    "                train_pearson = \"Could not calculate Pearsonr\"\n",
    "            \n",
    "            try:\n",
    "                valid_pearson = pearsonr(valid_results['predictions'], valid_results['targets'])\n",
    "            except FloatingPointError:\n",
    "                valid_pearson = \"Could not calculate Pearsonr\"\n",
    "            \n",
    "            # calculate average losses\n",
    "            train_loss = np.mean(train_loss)\n",
    "            valid_loss = np.mean(valid_loss)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "            # print training/validation statistics            \n",
    "            logging.info(f\"Epoch {epoch} - completed in {(time.time() - epoch_start):.0f} seconds\\n\"\n",
    "                         f\"Training Loss: {train_loss:.6f}\\t Pearson: {train_pearson}\\n\"\n",
    "                         f\"Validation loss: {valid_loss:.6f}\\t Pearson: {valid_pearson}\")\n",
    "            \n",
    "            # save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                logging.info(f'!! Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).')\n",
    "                logging.info(f'!! Saving model as {self.checkpoint_f}...')\n",
    "                \n",
    "                torch.save(self.model.state_dict(), self.checkpoint_f)\n",
    "                last_saved_epoch = epoch                         \n",
    "                valid_loss_min = valid_loss\n",
    "            else:\n",
    "                logging.info(f\"!! Valid loss not improved. (Min. = {valid_loss_min}; last save at ep. {last_saved_epoch})\")\n",
    "                if train_loss <= valid_loss:\n",
    "                    logging.warning(f\"!! Training loss is lte validation loss. Might be overfitting!\")\n",
    "            \n",
    "            # Early-stopping\n",
    "            if patience is not None:\n",
    "                if (epoch - last_saved_epoch) == patience:\n",
    "                    logging.info(f\"Stopping early at epoch {epoch} (patience={patience})...\")\n",
    "                    break\n",
    "            \n",
    "            # Optimise with scheduler\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(valid_loss)\n",
    "            \n",
    "        RegressionRNN._plot_training(train_losses, valid_losses)\n",
    "        \n",
    "        logging.info(f\"Training completed in {(time.time() - train_start):.0f} seconds\"\n",
    "                     f\"\\nMin. valid loss: {valid_loss_min}\\nLast saved epoch: {last_saved_epoch}\"\n",
    "                     f\"\\nPerformance: {len(self.datasets['train'])//total_train_time:.0f} sentences/s\")\n",
    "\n",
    "    def _process(self, do, log_update_freq, epoch=None):\n",
    "        if do not in ('train', 'valid', 'test'):\n",
    "            raise ValueError(\"Use 'train', 'valid', or 'test' for 'do'.\")\n",
    "        \n",
    "        results = {'predictions': np.array([]), 'targets': np.array([])}\n",
    "        losses = np.array([])\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if do == 'train':\n",
    "            self.model.train()            \n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        \n",
    "        if log_update_freq:\n",
    "            nro_batches = len(self.datasets[do]) // self.dataloaders[do].batch_size\n",
    "            update_interval = nro_batches * (log_update_freq/100)\n",
    "            update_checkpoints = {int(nro_batches-(i*update_interval)) for i in range((100//log_update_freq))}\n",
    "        \n",
    "        for batch_idx, data in enumerate(self.dataloaders[do], 1):\n",
    "            # 0. Clear gradients\n",
    "            if do == 'train':                \n",
    "                self.optimizer.zero_grad()\n",
    "                if self.use_bert and self.bert_optimizer is not None:\n",
    "                    self.bert_optimizer.zero_grad()                     \n",
    "                \n",
    "            # 1. Data prep\n",
    "            if self.use_ms:\n",
    "                ms = data['ms']\n",
    "            if self.use_sentences:\n",
    "                sentences = data['sentences']\n",
    "\n",
    "            target = data['labels']\n",
    "            \n",
    "            sorted_ids = None\n",
    "            # Convert ms features to int array\n",
    "            if self.use_ms: \n",
    "                ms, sorted_ids = self.prepare_ms(ms)\n",
    "                ms = ms.to(self.device)\n",
    "            else:\n",
    "                ms = None\n",
    "            \n",
    "            # Convert sentence to token array\n",
    "            if self.use_sentences:\n",
    "                sentences = self.prepare_lines(sentences, split_on=' ')\n",
    "            \n",
    "            # Convert tokens to word2vec IDs\n",
    "            if self.use_w2v:\n",
    "                packed_w2v_ids, sorted_ids = self.prepare_w2v(sentences)\n",
    "                packed_w2v_ids = packed_w2v_ids.to(self.device)\n",
    "            else:\n",
    "                packed_w2v_ids = None\n",
    "                    \n",
    "            if self.use_elmo:\n",
    "                elmo_sentences = RegressionRNN.prepare_elmo(sentences)\n",
    "                elmo_ids = batch_to_ids(elmo_sentences)                     \n",
    "                elmo_ids = elmo_ids[sorted_ids] if sorted_ids is not None else elmo_ids\n",
    "                elmo_ids = elmo_ids.to(self.device)\n",
    "            else:\n",
    "                elmo_ids = None\n",
    "            \n",
    "            if self.use_bert:\n",
    "                bert_ids, bert_mask = self.prepare_bert(sentences)                     \n",
    "                bert_ids = bert_ids[sorted_ids] if sorted_ids is not None else bert_ids\n",
    "                bert_mask = bert_mask[sorted_ids] if sorted_ids is not None else bert_mask\n",
    "                     \n",
    "                bert_ids = bert_ids.to(self.device)\n",
    "                bert_mask = bert_mask.to(self.device)\n",
    "                bert_input = (bert_ids, bert_mask)\n",
    "            else:\n",
    "                bert_input = None\n",
    "            \n",
    "            # Convert target to float array\n",
    "            target = torch.FloatTensor(self.prepare_lines(target, cast_to=float))\n",
    "            target = target[sorted_ids] if sorted_ids is not None else target\n",
    "            # Get current batch size\n",
    "            curr_batch_size = target.size(0)           \n",
    "                     \n",
    "            target = target.to(self.device)   \n",
    "\n",
    "            # 2. Predictions\n",
    "            pred = self.model(curr_batch_size, ms, packed_w2v_ids, elmo_ids, bert_input)\n",
    "            loss = self.criterion(pred, target)\n",
    "                    \n",
    "            # 3. Optimise during training\n",
    "            if do == 'train':\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.use_bert and self.bert_optimizer is not None:\n",
    "                    self.bert_optimizer.step()\n",
    "            \n",
    "            # 4. Save results\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            \n",
    "            results['predictions'] = np.append(results['predictions'], pred, axis=None)            \n",
    "            results['targets'] = np.append(results['targets'], target, axis=None)\n",
    "            losses = np.append(losses, float(loss))\n",
    "\n",
    "            if log_update_freq and batch_idx in update_checkpoints:\n",
    "                if do in ('train', 'valid'):\n",
    "                    logging.info(f\"{do.capitalize()} epoch {epoch}, batch nr. {batch_idx}/{nro_batches}...\")\n",
    "                else:                        \n",
    "                    logging.info(f\"{do.capitalize()}, batch nr. {batch_idx}/{nro_batches}...\")\n",
    "        \n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        return losses, results\n",
    "\n",
    "    def test(self, checkpoint_f='checkpoint.pth', log_update_freq=0):\n",
    "        logging.info('Testing started.')\n",
    "        test_start = time.time()\n",
    "        \n",
    "        if self.checkpoint_f is None:\n",
    "            self.model.load_state_dict(torch.load(checkpoint_f, map_location=self.device))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(self.checkpoint_f, map_location=self.device))\n",
    "\n",
    "        test_loss, test_results = self._process('test', log_update_freq)\n",
    "\n",
    "        try:\n",
    "            test_pearson = pearsonr(test_results['predictions'], test_results['targets'])\n",
    "        except FloatingPointError:\n",
    "            test_pearson = \"Could not calculate Pearsonr\"\n",
    "        \n",
    "        test_loss = np.mean(test_loss)\n",
    "        \n",
    "        logging.info(f\"Testing completed in {(time.time() - test_start):.0f} seconds\"\n",
    "                     f\"\\nLoss: {test_loss:.6f}\\t Pearson: {test_pearson}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-05-22 16:52:54,491: Training set size: 113633\n",
      "[INFO] 2019-05-22 16:52:54,492: Validation set size: 8000\n",
      "[INFO] 2019-05-22 16:52:54,493: Test set size: 8000\n",
      "[INFO] 2019-05-22 16:52:54,494: Using GPU GeForce GTX 1080 Ti\n",
      "[INFO] 2019-05-22 16:52:54,506: Morphosyntactic features enabled...\n",
      "[INFO] 2019-05-22 16:52:54,520: Word embeddings enabled...\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 512\n",
    "MS_SIZE = 102 if use_ms else None\n",
    "\n",
    "files = {\n",
    "    'train_files': {\n",
    "        'ms': r'C:\\wsl-shared\\cross-conll\\train\\conll-feats.train', \n",
    "        'sentences': r'C:\\wsl-shared\\cross-conll\\train\\dpc.tok.norm.clean.cut.en.train',\n",
    "        'labels': r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'\n",
    "    },\n",
    "    'valid_files': {\n",
    "        'ms': r'C:\\wsl-shared\\cross-conll\\dev\\conll-feats.dev', \n",
    "        'sentences': r'C:\\wsl-shared\\cross-conll\\dev\\dpc.tok.norm.clean.cut.en.dev',\n",
    "        'labels': r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'\n",
    "    },\n",
    "    'test_files': {\n",
    "        'ms': r'C:\\wsl-shared\\cross-conll\\test\\conll-feats.test',\n",
    "        'sentences': r'C:\\wsl-shared\\cross-conll\\test\\dpc.tok.norm.clean.cut.en.test',\n",
    "        'labels': r'C:\\wsl-shared\\cross-conll\\test\\cross.txt',\n",
    "    }\n",
    "}\n",
    "\n",
    "regr = RegressionRNN(**files,\n",
    "                     ms_dim = MS_SIZE,\n",
    "                     use_w2v=use_w2v,\n",
    "                     use_elmo=use_elmo,\n",
    "                     bert=bert_config,\n",
    "                     batch_size=(64, 64, 64))\n",
    "\n",
    "if use_w2v:\n",
    "    regr.w2v_vocab = w2v_config['model'].vocab        \n",
    "\n",
    "regr.model = Regressor(HIDDEN_DIM, \n",
    "                       ms_dim=MS_SIZE, \n",
    "                       w2v=w2v_config,\n",
    "                       elmo=elmo_config,\n",
    "                       bert=bert_config,\n",
    "                       bidirectional=True,\n",
    "                       drop_prob=0)\n",
    "\n",
    "regr.criterion = nn.MSELoss()\n",
    "regr.optimizer = BertAdam([p for p in regr.model.parameters() if p.requires_grad],\n",
    "                          lr=0.00002,\n",
    "                          weight_decay=0.0002)\n",
    "\n",
    "\n",
    "# regr.optimizer = optim.Adam([\n",
    "#     {'params': [p for name, p in regr.model.named_parameters() if p.requires_grad and not name.startswith('bert')],\n",
    "#      'lr': 0.001},\n",
    "#     {'params': [p for p in regr.model.bert.parameters() if p.requires_grad],\n",
    "#      'lr': 0.00002,\n",
    "#      'weight_decay': 0.0002}\n",
    "# ])\n",
    "\n",
    "# regr.scheduler = optim.lr_scheduler.ReduceLROnPlateau(regr.optimizer, 'min', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-05-22 16:52:56,777: Training started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unpacked_ms_out torch.Size([64, 29, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 29, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 30, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 30, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 29, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 29, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 30, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 30, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 30, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 30, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 30, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 30, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 28, 1024])\n",
      "unpacked_w2v_out torch.Size([64, 28, 1024])\n",
      "sentence_ms_cat torch.Size([64, 1024])\n",
      "unpacked_ms_out torch.Size([64, 30, 1024])\n",
      "unpacked_w2v_out "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-fe5e1e4f8379>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_update_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-1a3d23b20631>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, checkpoint_f, log_update_freq, patience)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mepoch_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_update_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mtotal_train_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepoch_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-1a3d23b20631>\u001b[0m in \u001b[0;36m_process\u001b[1;34m(self, do, log_update_freq, epoch)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[1;31m# 2. Predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacked_w2v_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melmo_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbert_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bram\\.virtualenvs\\pylt3-akadaxte\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-83094daaca50>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch_size, ms_input, packed_w2v_ids, elmo_ids, bert_input)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m#             print('after gru', packed_w2v_out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0munpacked_w2v_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_w2v_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unpacked_w2v_out'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munpacked_w2v_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0munpacked_w2v_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpacked_w2v_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munpacked_w2v_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bram\\.virtualenvs\\pylt3-akadaxte\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bram\\.virtualenvs\\pylt3-akadaxte\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bram\\.virtualenvs\\pylt3-akadaxte\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bram\\.virtualenvs\\pylt3-akadaxte\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bram\\.virtualenvs\\pylt3-akadaxte\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python37\\Lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python37\\Lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regr.train(epochs=100, log_update_freq=25, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.test(log_update_freq=25)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sentences + MS\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\conll-feats.train',\n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\dpc.tok.norm.clean.cut.en.train',                                  \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\conll-feats.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\dpc.tok.norm.clean.cut.en.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\conll-feats.test',\n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\dpc.tok.norm.clean.cut.en.test',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}\n",
    "\n",
    "# MS\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\conll-feats.train',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\conll-feats.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\conll-feats.test',                               \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}\n",
    "\n",
    "# Sentences\n",
    "files = {\n",
    "    'train_files': (r'C:\\wsl-shared\\cross-conll\\train\\dpc.tok.norm.clean.cut.en.train',                                  \n",
    "                    r'C:\\wsl-shared\\cross-conll\\train\\cross.txt'),\n",
    "     'valid_files': (r'C:\\wsl-shared\\cross-conll\\dev\\dpc.tok.norm.clean.cut.en.dev',\n",
    "                     r'C:\\wsl-shared\\cross-conll\\dev\\cross.txt'),\n",
    "     'test_files': (r'C:\\wsl-shared\\cross-conll\\test\\dpc.tok.norm.clean.cut.en.test',                                 \n",
    "                    r'C:\\wsl-shared\\cross-conll\\test\\cross.txt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
